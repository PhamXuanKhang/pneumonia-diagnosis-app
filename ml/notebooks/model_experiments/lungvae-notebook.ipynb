{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09dabe6f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-27T16:53:42.643119Z",
     "iopub.status.busy": "2025-10-27T16:53:42.642898Z",
     "iopub.status.idle": "2025-10-27T16:53:42.652424Z",
     "shell.execute_reply": "2025-10-27T16:53:42.651763Z"
    },
    "papermill": {
     "duration": 0.014134,
     "end_time": "2025-10-27T16:53:42.653481",
     "exception": false,
     "start_time": "2025-10-27T16:53:42.639347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ===========================================\n",
    "# #  LungVAE (PyTorch, state_dict) => Predict 3 NORMAL & 3 PNEUMONIA\n",
    "# #  Dùng class uVAE mà bạn đã cung cấp\n",
    "# # ===========================================\n",
    "# import os, cv2, glob, numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ==== (1) Dán class uVAE và convBlock bạn gửi vào đây (không đổi gì) ====\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.distributions import Normal, Independent\n",
    "# from torch.distributions.kl import kl_divergence as KLD\n",
    "# import numpy as np\n",
    "# from torch.nn.functional import softplus, sigmoid, softmax\n",
    "# import pdb\n",
    "# import torch.nn.functional as F\n",
    "# _device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# class convBlock(nn.Module):\n",
    "#     def __init__(self, inCh, nhid, nOp, pool=True,\n",
    "#                     ker=3,padding=1,pooling=2):\n",
    "#         super(convBlock,self).__init__()\n",
    "\n",
    "#         self.enc1 = nn.Conv2d(inCh,nhid,kernel_size=ker,padding=1)\n",
    "#         self.enc2 = nn.Conv2d(nhid,nOp,kernel_size=ker,padding=1)\n",
    "#         self.bn = nn.BatchNorm2d(inCh)    \n",
    "\n",
    "#         if pool:\n",
    "#             self.scale = nn.AvgPool2d(kernel_size=pooling)\n",
    "#         else:\n",
    "#             self.scale = nn.Upsample(scale_factor=pooling)\n",
    "#         self.pool = pool\n",
    "#         self.act = nn.ReLU()\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x = self.scale(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.act(self.enc1(x))\n",
    "#         x = self.act(self.enc2(x))\n",
    "#         return x\n",
    "\n",
    "# class uVAE(nn.Module):\n",
    "#     def __init__(self, nlatent,unet=False, \n",
    "#                     nhid=8, ker=3, inCh=1,h=640,w=512):\n",
    "#         super(uVAE, self).__init__()\n",
    "#         self.latent_space = nlatent\n",
    "#         self.unet = unet\n",
    "\n",
    "#         if not self.unet:\n",
    "#             # VAE Encoder\n",
    "#             self.enc11 = nn.Conv2d(inCh,nhid,kernel_size=ker,padding=1)\n",
    "#             self.enc12 = nn.Conv2d(nhid,nhid,kernel_size=ker,padding=1)\n",
    "\n",
    "#             self.enc2 = convBlock(nhid,2*nhid,2*nhid,pool=True)\n",
    "#             self.enc3 = convBlock(2*nhid,4*nhid,4*nhid,pool=True)\n",
    "#             self.enc4 = convBlock(4*nhid,8*nhid,8*nhid,pool=True)\n",
    "#             self.enc5 = convBlock(8*nhid,16*nhid,16*nhid,pool=True)\n",
    "\n",
    "#             self.bot11 = nn.Conv1d(16*nhid,1,kernel_size=1)\n",
    "#             self.bot12 = nn.Conv1d(int((h/16)*(w/16)),2*nlatent,kernel_size=1)\n",
    "\n",
    "#             # Decoder (VAE path)\n",
    "#             self.bot21 = nn.Conv1d(nlatent,int((h/64)*(w/64)),kernel_size=1)\n",
    "#             self.bot22 = nn.Conv1d(1,nhid,kernel_size=1)\n",
    "#             self.bot23 = nn.Conv1d(nhid,4*nhid,kernel_size=1)\n",
    "#             self.bot24 = nn.Conv1d(4*nhid,16*nhid,kernel_size=1)\n",
    "\n",
    "#         # U-Net Encoder\n",
    "#         self.uEnc11 = nn.Conv2d(inCh,nhid,kernel_size=ker,padding=1)\n",
    "#         self.uEnc12 = nn.Conv2d(nhid,nhid,kernel_size=ker,padding=1)\n",
    "\n",
    "#         self.uEnc2 = convBlock(nhid,2*nhid,2*nhid,pool=True,pooling=4)\n",
    "#         self.uEnc3 = convBlock(2*nhid,4*nhid,4*nhid,pool=True,pooling=4)\n",
    "#         self.uEnc4 = convBlock(4*nhid,8*nhid,8*nhid,pool=True)\n",
    "#         self.uEnc5 = convBlock(8*nhid,16*nhid,16*nhid,pool=True)\n",
    "\n",
    "#         # Joint decoder\n",
    "#         if not self.unet:\n",
    "#             self.dec5 = convBlock(32*nhid,8*nhid,8*nhid,pool=False)\n",
    "#         else:\n",
    "#             self.dec5 = convBlock(16*nhid,8*nhid,8*nhid,pool=False)\n",
    "\n",
    "#         self.dec4 = convBlock(16*nhid,4*nhid,4*nhid,pool=False)\n",
    "#         self.dec3 = convBlock(8*nhid,2*nhid,2*nhid,pool=False,pooling=4)\n",
    "#         self.dec2 = convBlock(4*nhid,nhid,nhid,pool=False,pooling=4)\n",
    "\n",
    "#         self.dec11 = nn.Conv2d(2*nhid,nhid,kernel_size=ker,padding=1)\n",
    "#         self.dec12 = nn.Conv2d(nhid,inCh,kernel_size=ker,padding=1)\n",
    "        \n",
    "#         self.act = nn.ReLU()\n",
    "#         self.mu_0 = torch.zeros((1,nlatent)).to(_device)\n",
    "#         self.sigma_0 = torch.ones((1,nlatent)).to(_device)\n",
    "\n",
    "#         self.h = h\n",
    "#         self.w = w\n",
    "\n",
    "#     def vae_encoder(self,x):\n",
    "#         x = self.act(self.enc11(x))\n",
    "#         x = self.act(self.enc12(x))\n",
    "#         x = self.enc2(x)\n",
    "#         x = self.enc3(x)\n",
    "#         x = self.enc4(x)\n",
    "#         x = self.enc5(x)\n",
    "\n",
    "#         z = self.act(self.bot11(x.view(x.shape[0],x.shape[1],-1)))\n",
    "#         z = self.bot12(z.permute(0,2,1))\n",
    "#         return z.squeeze(-1)\n",
    "\n",
    "#     def unet_encoder(self,x_in):\n",
    "#         x = []\n",
    "#         x.append(self.act(self.uEnc12(self.act(self.uEnc11(x_in)))))\n",
    "#         x.append(self.uEnc2(x[-1]))\n",
    "#         x.append(self.uEnc3(x[-1]))\n",
    "#         x.append(self.uEnc4(x[-1]))\n",
    "#         x.append(self.uEnc5(x[-1]))\n",
    "#         return x\n",
    "\n",
    "#     def decoder(self,x_enc,z=None):\n",
    "#         if not self.unet:\n",
    "#             x = self.act(self.bot21(z.unsqueeze(2)))\n",
    "#             x = self.act(self.bot22(x.permute(0,2,1)))\n",
    "#             x = self.act(self.bot23(x))\n",
    "#             x = self.act(self.bot24(x))\n",
    "#             x = x.view(x.shape[0],x.shape[1],int(self.h/64),int(self.w/64))\n",
    "#             x = torch.cat((x,x_enc[-1]),dim=1)\n",
    "#             x = self.dec5(x)\n",
    "#         else:\n",
    "#             x = self.dec5(x_enc[-1])\n",
    "#         x = torch.cat((x,x_enc[-2]),dim=1)\n",
    "#         x = self.dec4(x)\n",
    "#         x = torch.cat((x,x_enc[-3]),dim=1)\n",
    "#         x = self.dec3(x)\n",
    "#         x = torch.cat((x,x_enc[-4]),dim=1)\n",
    "#         x = self.dec2(x)\n",
    "#         x = torch.cat((x,x_enc[-5]),dim=1)\n",
    "#         x = self.act(self.dec11(x))\n",
    "#         x = self.dec12(x)\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         kl = torch.zeros(1).to(_device)\n",
    "#         z = 0.\n",
    "#         x_enc = self.unet_encoder(x)\n",
    "#         if not self.unet:\n",
    "#             emb = self.vae_encoder(x)\n",
    "#             mu, log_var = torch.chunk(emb, 2, dim=1)\n",
    "#             log_var = softplus(log_var)\n",
    "#             sigma = torch.exp(log_var / 2)\n",
    "#             posterior = Independent(Normal(loc=mu,scale=sigma),1)\n",
    "#             z = posterior.rsample()\n",
    "#             prior = Independent(Normal(loc=self.mu_0,scale=self.sigma_0),1)\n",
    "#             kl = KLD(posterior,prior).sum()\n",
    "#         xHat = self.decoder(x_enc,z)\n",
    "#         return kl, xHat\n",
    "# # ==== (hết phần class) ===================================\n",
    "\n",
    "# # ----------------------------\n",
    "# # 2) Đường dẫn & cấu hình\n",
    "# # ----------------------------\n",
    "# WEIGHTS_PATH = \"/kaggle/input/lungvae/lungVAE.pt\"\n",
    "# NORMAL_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/NORMAL\"\n",
    "# PNEU_DIR   = \"/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/PNEUMONIA\"\n",
    "# SAVE_DIR = \"./masks_demo_lungvae\"\n",
    "# os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(\"[INFO] Device:\", DEVICE)\n",
    "\n",
    "# # ----------------------------\n",
    "# # 3) Suy luận hyperparam từ state_dict & khởi tạo model\n",
    "# # ----------------------------\n",
    "# def infer_hparams_from_state_dict(sd):\n",
    "#     \"\"\"\n",
    "#     Trích nlatent, nhid, h, w, unet từ state_dict.\n",
    "#     - nlatent: in_channels của bot21.weight (nếu tồn tại) -> VAE on (unet=False)\n",
    "#     - nhid: out_channels của uEnc11.weight\n",
    "#     - (h/16)*(w/16): in_channels của bot12.weight (nếu có)\n",
    "#     - Nếu không có bot21/bot12 -> khả năng model train ở chế độ unet=True (không VAE)\n",
    "#     \"\"\"\n",
    "#     nhid = sd[\"uEnc11.weight\"].shape[0] if \"uEnc11.weight\" in sd else 8\n",
    "\n",
    "#     # Mặc định đoán unet=False nếu thấy các layer VAE\n",
    "#     has_vae = (\"bot21.weight\" in sd) or (\"bot12.weight\" in sd)\n",
    "#     unet_flag = not has_vae  # nếu không có VAE layers -> unet=True\n",
    "\n",
    "#     # nlatent\n",
    "#     nlatent = 16\n",
    "#     if \"bot21.weight\" in sd:\n",
    "#         # shape: [out_c, in_c, 1] -> in_c = nlatent\n",
    "#         nlatent = sd[\"bot21.weight\"].shape[1]\n",
    "\n",
    "#     # h,w từ bot12.weight (Conv1d in_channels = (h/16)*(w/16))\n",
    "#     h, w = 640, 512\n",
    "#     if \"bot12.weight\" in sd:\n",
    "#         in_c = sd[\"bot12.weight\"].shape[1]\n",
    "#         # Tìm (h,w) chia hết cho 16, sao cho (h/16)*(w/16) = in_c\n",
    "#         candidates = []\n",
    "#         for H in [512, 576, 600, 640, 672, 704, 720, 736, 768, 800, 832, 896, 960, 1024]:\n",
    "#             for W in [384, 400, 448, 480, 512, 544, 576, 600, 640, 672, 704, 720, 736, 768, 800, 896, 960, 1024]:\n",
    "#                 if (H % 16 == 0) and (W % 16 == 0):\n",
    "#                     if (H//16)*(W//16) == in_c:\n",
    "#                         candidates.append((H,W))\n",
    "#         if candidates:\n",
    "#             # ưu tiên (640,512) nếu có\n",
    "#             if (640,512) in candidates:\n",
    "#                 h, w = 640, 512\n",
    "#             else:\n",
    "#                 h, w = candidates[0]\n",
    "#     return nlatent, nhid, h, w, unet_flag\n",
    "\n",
    "# # Tải state_dict\n",
    "# obj = torch.load(WEIGHTS_PATH, map_location=\"cpu\")\n",
    "# if \"state_dict\" in obj:\n",
    "#     sd = obj[\"state_dict\"]\n",
    "# else:\n",
    "#     # Có thể là state_dict thuần\n",
    "#     if isinstance(obj, dict):\n",
    "#         sd = obj\n",
    "#     else:\n",
    "#         raise RuntimeError(\"File weights không phải state_dict. (Nếu là full model, bạn có thể load trực tiếp.)\")\n",
    "\n",
    "# # Khởi tạo model theo state_dict\n",
    "# nlatent, nhid, Himg, Wimg, unet_flag = infer_hparams_from_state_dict(sd)\n",
    "# print(f\"[INFO] Inferred: nlatent={nlatent}, nhid={nhid}, H×W={Himg}×{Wimg}, unet={unet_flag}\")\n",
    "\n",
    "# model = uVAE(nlatent=nlatent, unet=unet_flag, nhid=nhid, inCh=1, h=Himg, w=Wimg)\n",
    "# missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "# print(\"[INFO] load_state_dict: missing =\", missing[:6], (\"...(+%d)\"%(max(0,len(missing)-6))) if len(missing)>6 else \"\")\n",
    "# print(\"[INFO] load_state_dict: unexpected =\", unexpected)\n",
    "# model.to(DEVICE).eval()\n",
    "\n",
    "# # ----------------------------\n",
    "# # 4) Helpers (giữ API giống phiên bản TF/Keras)\n",
    "# # ----------------------------\n",
    "# def is_image_file(p): \n",
    "#     return p.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"))\n",
    "\n",
    "# def pick_samples(folder, k=3, seed=2025):\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     files = sorted([os.path.join(folder,f) for f in os.listdir(folder) if is_image_file(f)])\n",
    "#     assert len(files) > 0, f\"No images in {folder}\"\n",
    "#     k = min(k, len(files))\n",
    "#     idx = rng.choice(len(files), size=k, replace=False)\n",
    "#     return [files[i] for i in idx]\n",
    "\n",
    "# def read_gray(path):\n",
    "#     img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "#     if img is None: raise ValueError(f\"Cannot read: {path}\")\n",
    "#     return img\n",
    "\n",
    "# def preprocess_resize(img_np, H, W):\n",
    "#     \"\"\"\n",
    "#     Resize ảnh về (H,W), normalize [0,1], tensor (1,1,H,W)\n",
    "#     \"\"\"\n",
    "#     rs = cv2.resize(img_np, (W, H), interpolation=cv2.INTER_AREA)\n",
    "#     x  = torch.from_numpy(rs.astype(np.float32) / 255.0)[None, None, ...]\n",
    "#     return x.to(DEVICE)\n",
    "\n",
    "# def postprocess_mask(prob_map_np, orig_shape, thr=0.5):\n",
    "#     \"\"\"\n",
    "#     prob_map_np: (Himg,Wimg) in [0,1] (cùng size với model)\n",
    "#     Resize về kích thước gốc, threshold -> uint8 mask (0/255)\n",
    "#     \"\"\"\n",
    "#     H0, W0 = orig_shape\n",
    "#     p = cv2.resize(prob_map_np.astype(np.float32), (W0, H0), interpolation=cv2.INTER_LINEAR)\n",
    "#     mask = (p >= thr).astype(np.uint8) * 255\n",
    "#     return mask\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def infer_mask(model, x):\n",
    "#     \"\"\"\n",
    "#     model(x) -> (kl, xHat)\n",
    "#     xHat shape: (B,1,H,W). Với bài toán segment, xHat là logits/prob mask\n",
    "#     \"\"\"\n",
    "#     kl, xHat = model(x)\n",
    "#     # Nếu giá trị không trong [0,1], coi là logits và áp sigmoid\n",
    "#     if (xHat.min() < 0.0) or (xHat.max() > 1.0):\n",
    "#         xHat = torch.sigmoid(xHat)\n",
    "#     prob = xHat.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "#     return prob\n",
    "\n",
    "# def predict_mask(img_path, thr=0.5, save=True, prefix=\"\"):\n",
    "#     img = read_gray(img_path)\n",
    "#     H0, W0 = img.shape[:2]\n",
    "#     x = preprocess_resize(img, Himg, Wimg)\n",
    "#     prob = infer_mask(model, x)             # (Himg,Wimg) in [0,1]\n",
    "#     mask = postprocess_mask(prob, (H0, W0), thr)\n",
    "#     if save:\n",
    "#         name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "#         outp = os.path.join(SAVE_DIR, f\"{prefix}{name}_mask.png\")\n",
    "#         cv2.imwrite(outp, mask)\n",
    "#     return img, mask\n",
    "\n",
    "# def to3(x): \n",
    "#     return np.stack([x,x,x],axis=-1) if x.ndim==2 else x\n",
    "\n",
    "# def make_pair(original, mask):\n",
    "#     return np.hstack([to3(original), to3(mask)])\n",
    "\n",
    "# def build_montage(paths, prefix=\"\"):\n",
    "#     rows = []\n",
    "#     for p in paths:\n",
    "#         img,mask = predict_mask(p, prefix=prefix)\n",
    "#         rows.append(make_pair(img, mask))\n",
    "#     # pad theo độ rộng lớn nhất (phòng khi size khác nhau)\n",
    "#     maxw = max(r.shape[1] for r in rows)\n",
    "#     rows2=[]\n",
    "#     for r in rows:\n",
    "#         h,w,c=r.shape\n",
    "#         if w<maxw:\n",
    "#             pad = np.zeros((h, maxw-w, c), dtype=r.dtype)\n",
    "#             r = np.hstack([r,pad])\n",
    "#         rows2.append(r)\n",
    "#     return np.vstack(rows2)\n",
    "\n",
    "# # ----------------------------\n",
    "# # 5) Lấy mẫu & tạo montage\n",
    "# # ----------------------------\n",
    "# normal_paths = pick_samples(NORMAL_DIR, k=3, seed=2025)\n",
    "# pneu_paths   = pick_samples(PNEU_DIR,   k=3, seed=2025)\n",
    "\n",
    "# montage_normal = build_montage(normal_paths, prefix=\"NORMAL_\")\n",
    "# montage_pneu   = build_montage(pneu_paths,   prefix=\"PNEUMONIA_\")\n",
    "\n",
    "# # Lưu montage\n",
    "# mn_path = os.path.join(SAVE_DIR,\"montage_NORMAL_orig_mask.png\")\n",
    "# mp_path = os.path.join(SAVE_DIR,\"montage_PNEUMONIA_orig_mask.png\")\n",
    "# cv2.imwrite(mn_path, montage_normal[:,:,::-1])\n",
    "# cv2.imwrite(mp_path, montage_pneu[:,:,::-1])\n",
    "\n",
    "# # ----------------------------\n",
    "# # 6) Hiển thị\n",
    "# # ----------------------------\n",
    "# plt.figure(); plt.imshow(montage_normal); plt.axis('off'); plt.title(\"NORMAL: [Original | Mask] x3\")\n",
    "# plt.figure(); plt.imshow(montage_pneu);   plt.axis('off'); plt.title(\"PNEUMONIA: [Original | Mask] x3\")\n",
    "\n",
    "# print(\"[SAVED]\")\n",
    "# print(\" -\", mn_path)\n",
    "# print(\" -\", mp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a5ed3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T16:53:42.658344Z",
     "iopub.status.busy": "2025-10-27T16:53:42.658144Z",
     "iopub.status.idle": "2025-10-27T16:57:53.340357Z",
     "shell.execute_reply": "2025-10-27T16:57:53.339495Z"
    },
    "papermill": {
     "duration": 250.686009,
     "end_time": "2025-10-27T16:57:53.341650",
     "exception": false,
     "start_time": "2025-10-27T16:53:42.655641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device: cuda\n",
      "[INFO] Inferred: nlatent=8, nhid=16, H×W=640×512, unet=False\n",
      "[INFO] load_state_dict missing: 0 unexpected: 0\n",
      "[INFO] train/NORMAL: 1341 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1341/1341 [01:13<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train/PNEUMONIA: 3875 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3875/3875 [02:27<00:00, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val/NORMAL: 8 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 23.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val/PNEUMONIA: 8 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test/NORMAL: 234 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:10<00:00, 21.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test/PNEUMONIA: 390 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:13<00:00, 27.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Wrote dataset to: ./chest_xray_segmented_v1\n",
      " - META/segmenter.json\n",
      " - META/index.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "#  Precompute Segmentation Dataset (LungVAE)\n",
    "#  - Generate: mask_soft.npy (model output size)\n",
    "#  - Create: META/index.csv, META/segmenter.json\n",
    "#  (Bản thu gọn - Chỉ lưu mask mềm)\n",
    "# ===========================================\n",
    "import os, json, csv, time, math, hashlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Cấu hình\n",
    "# ----------------------------\n",
    "DATA_ROOT = \"/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray\"\n",
    "WEIGHTS_PATH = \"/kaggle/input/lungvae/lungVAE.pt\"\n",
    "SAVE_ROOT = \"./chest_xray_segmented_v1\"   # output dataset\n",
    "\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_ROOT, \"META\"), exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"[INFO] Device:\", DEVICE)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Dán class uVAE (bạn đã cung cấp) - giữ nguyên\n",
    "# ----------------------------\n",
    "from torch.distributions import Normal, Independent\n",
    "from torch.distributions.kl import kl_divergence as KLD\n",
    "from torch.nn.functional import softplus, sigmoid, softmax\n",
    "\n",
    "class convBlock(nn.Module):\n",
    "    def __init__(self, inCh, nhid, nOp, pool=True,\n",
    "                     ker=3,padding=1,pooling=2):\n",
    "        super(convBlock,self).__init__()\n",
    "        self.enc1 = nn.Conv2d(inCh,nhid,kernel_size=ker,padding=1)\n",
    "        self.enc2 = nn.Conv2d(nhid,nOp,kernel_size=ker,padding=1)\n",
    "        self.bn = nn.BatchNorm2d(inCh)\n",
    "        if pool:\n",
    "            self.scale = nn.AvgPool2d(kernel_size=pooling)\n",
    "        else:\n",
    "            self.scale = nn.Upsample(scale_factor=pooling)\n",
    "        self.pool = pool\n",
    "        self.act = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x = self.scale(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(self.enc1(x))\n",
    "        x = self.act(self.enc2(x))\n",
    "        return x\n",
    "\n",
    "class uVAE(nn.Module):\n",
    "    def __init__(self, nlatent,unet=False, \n",
    "                     nhid=8, ker=3, inCh=1,h=640,w=512):\n",
    "        super(uVAE, self).__init__()\n",
    "        self.latent_space = nlatent\n",
    "        self.unet = unet\n",
    "        if not self.unet:\n",
    "            self.enc11 = nn.Conv2d(inCh,nhid,kernel_size=ker,padding=1)\n",
    "            self.enc12 = nn.Conv2d(nhid,nhid,kernel_size=ker,padding=1)\n",
    "            self.enc2 = convBlock(nhid,2*nhid,2*nhid,pool=True)\n",
    "            self.enc3 = convBlock(2*nhid,4*nhid,4*nhid,pool=True)\n",
    "            self.enc4 = convBlock(4*nhid,8*nhid,8*nhid,pool=True)\n",
    "            self.enc5 = convBlock(8*nhid,16*nhid,16*nhid,pool=True)\n",
    "            self.bot11 = nn.Conv1d(16*nhid,1,kernel_size=1)\n",
    "            self.bot12 = nn.Conv1d(int((h/16)*(w/16)),2*nlatent,kernel_size=1)\n",
    "            self.bot21 = nn.Conv1d(nlatent,int((h/64)*(w/64)),kernel_size=1)\n",
    "            self.bot22 = nn.Conv1d(1,nhid,kernel_size=1)\n",
    "            self.bot23 = nn.Conv1d(nhid,4*nhid,kernel_size=1)\n",
    "            self.bot24 = nn.Conv1d(4*nhid,16*nhid,kernel_size=1)\n",
    "        self.uEnc11 = nn.Conv2d(inCh,nhid,kernel_size=ker,padding=1)\n",
    "        self.uEnc12 = nn.Conv2d(nhid,nhid,kernel_size=ker,padding=1)\n",
    "        self.uEnc2 = convBlock(nhid,2*nhid,2*nhid,pool=True,pooling=4)\n",
    "        self.uEnc3 = convBlock(2*nhid,4*nhid,4*nhid,pool=True,pooling=4)\n",
    "        self.uEnc4 = convBlock(4*nhid,8*nhid,8*nhid,pool=True)\n",
    "        self.uEnc5 = convBlock(8*nhid,16*nhid,16*nhid,pool=True)\n",
    "        if not self.unet:\n",
    "            self.dec5 = convBlock(32*nhid,8*nhid,8*nhid,pool=False)\n",
    "        else:\n",
    "            self.dec5 = convBlock(16*nhid,8*nhid,8*nhid,pool=False)\n",
    "        self.dec4 = convBlock(16*nhid,4*nhid,4*nhid,pool=False)\n",
    "        self.dec3 = convBlock(8*nhid,2*nhid,2*nhid,pool=False,pooling=4)\n",
    "        self.dec2 = convBlock(4*nhid,nhid,nhid,pool=False,pooling=4)\n",
    "        self.dec11 = nn.Conv2d(2*nhid,nhid,kernel_size=ker,padding=1)\n",
    "        self.dec12 = nn.Conv2d(nhid,inCh,kernel_size=ker,padding=1)\n",
    "        self.act = nn.ReLU()\n",
    "        self.mu_0 = torch.zeros((1,nlatent))\n",
    "        self.sigma_0 = torch.ones((1,nlatent))\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "    def vae_encoder(self,x):\n",
    "        x = self.act(self.enc11(x)); x = self.act(self.enc12(x))\n",
    "        x = self.enc2(x); x = self.enc3(x); x = self.enc4(x); x = self.enc5(x)\n",
    "        z = self.act(self.bot11(x.view(x.shape[0],x.shape[1],-1)))\n",
    "        z = self.bot12(z.permute(0,2,1)); return z.squeeze(-1)\n",
    "    def unet_encoder(self,x_in):\n",
    "        x = []; x.append(self.act(self.uEnc12(self.act(self.uEnc11(x_in)))))\n",
    "        x.append(self.uEnc2(x[-1])); x.append(self.uEnc3(x[-1]))\n",
    "        x.append(self.uEnc4(x[-1])); x.append(self.uEnc5(x[-1]))\n",
    "        return x\n",
    "    def decoder(self,x_enc,z=None):\n",
    "        if not self.unet:\n",
    "            x = self.act(self.bot21(z.unsqueeze(2))); x = self.act(self.bot22(x.permute(0,2,1)))\n",
    "            x = self.act(self.bot23(x)); x = self.act(self.bot24(x))\n",
    "            x = x.view(x.shape[0],x.shape[1],int(self.h/64),int(self.w/64))\n",
    "            x = torch.cat((x,x_enc[-1]),dim=1); x = self.dec5(x)\n",
    "        else:\n",
    "            x = self.dec5(x_enc[-1])\n",
    "        x = torch.cat((x,x_enc[-2]),dim=1); x = self.dec4(x)\n",
    "        x = torch.cat((x,x_enc[-3]),dim=1); x = self.dec3(x)\n",
    "        x = torch.cat((x,x_enc[-4]),dim=1); x = self.dec2(x)\n",
    "        x = torch.cat((x,x_enc[-5]),dim=1); x = self.act(self.dec11(x)); x = self.dec12(x)\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        kl = torch.zeros(1, device=x.device); z = 0.\n",
    "        x_enc = self.unet_encoder(x)\n",
    "        if not self.unet:\n",
    "            emb = self.vae_encoder(x); mu, log_var = torch.chunk(emb, 2, dim=1)\n",
    "            log_var = softplus(log_var); sigma = torch.exp(log_var / 2)\n",
    "            posterior = Independent(Normal(loc=mu,scale=sigma),1)\n",
    "            z = posterior.rsample()\n",
    "            prior = Independent(Normal(loc=self.mu_0.to(x.device),scale=self.sigma_0.to(x.device)),1)\n",
    "            kl = KLD(posterior,prior).sum()\n",
    "        xHat = self.decoder(x_enc,z); return kl, xHat\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Utils (Đã thu gọn)\n",
    "# ----------------------------\n",
    "def is_image_file(p): \n",
    "    return p.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"))\n",
    "\n",
    "def sha256_of_file(path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk)\n",
    "            if not b: break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def ensure_dirs(base, split, label):\n",
    "    # Chỉ tạo thư mục mask_soft\n",
    "    base2 = os.path.join(base, split, label, \"mask_soft\")\n",
    "    os.makedirs(base2, exist_ok=True)\n",
    "    return base2\n",
    "\n",
    "def read_gray(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read: {path}\")\n",
    "    return img\n",
    "\n",
    "def preprocess_resize(img_np, H, W, device):\n",
    "    rs = cv2.resize(img_np, (W, H), interpolation=cv2.INTER_AREA)\n",
    "    x  = torch.from_numpy(rs.astype(np.float32)/255.0)[None, None, ...]  # (1,1,H,W)\n",
    "    return x.to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Load weights & infer hparams\n",
    "# ----------------------------\n",
    "def infer_hparams_from_state_dict(sd):\n",
    "    nhid = sd[\"uEnc11.weight\"].shape[0] if \"uEnc11.weight\" in sd else 8\n",
    "    has_vae = (\"bot21.weight\" in sd) or (\"bot12.weight\" in sd)\n",
    "    unet_flag = not has_vae\n",
    "    nlatent = 16\n",
    "    if \"bot21.weight\" in sd:\n",
    "        nlatent = sd[\"bot21.weight\"].shape[1]\n",
    "    h, w = 640, 512\n",
    "    if \"bot12.weight\" in sd:\n",
    "        in_c = sd[\"bot12.weight\"].shape[1]; candidates = []\n",
    "        for H in [512, 576, 600, 640, 672, 704, 720, 736, 768, 800, 832, 896, 960, 1024]:\n",
    "            for W in [384, 400, 448, 480, 512, 544, 576, 600, 640, 672, 704, 720, 736, 768, 800, 896, 960, 1024]:\n",
    "                if (H % 16 == 0) and (W % 16 == 0) and (H//16)*(W//16) == in_c:\n",
    "                    candidates.append((H,W))\n",
    "        if (640,512) in candidates: h,w = 640,512\n",
    "        elif candidates: h,w = candidates[0]\n",
    "    return nlatent, nhid, h, w, unet_flag\n",
    "\n",
    "obj = torch.load(WEIGHTS_PATH, map_location=\"cpu\")\n",
    "sd = obj[\"state_dict\"] if isinstance(obj, dict) and \"state_dict\" in obj else obj\n",
    "assert isinstance(sd, dict), \"Weights phải là state_dict hoặc checkpoint chứa state_dict.\"\n",
    "\n",
    "nlatent, nhid, Himg, Wimg, unet_flag = infer_hparams_from_state_dict(sd)\n",
    "print(f\"[INFO] Inferred: nlatent={nlatent}, nhid={nhid}, H×W={Himg}×{Wimg}, unet={unet_flag}\")\n",
    "\n",
    "model = uVAE(nlatent=nlatent, unet=unet_flag, nhid=nhid, inCh=1, h=Himg, w=Wimg)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"[INFO] load_state_dict missing:\", len(missing), \"unexpected:\", len(unexpected))\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Chuẩn bị META (Đã thu gọn)\n",
    "# ----------------------------\n",
    "weights_sha = sha256_of_file(WEIGHTS_PATH)\n",
    "meta = {\n",
    "    \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"seg_model\": \"uVAE (LungVAE)\",\n",
    "    \"weights_path\": WEIGHTS_PATH,\n",
    "    \"weights_sha256\": weights_sha,\n",
    "    \"params\": {\n",
    "        \"nlatent\": int(nlatent),\n",
    "        \"nhid\": int(nhid),\n",
    "        \"input_size\": [int(Himg), int(Wimg)],\n",
    "        \"unet_mode\": bool(unet_flag),\n",
    "    },\n",
    "    \"pipeline\": {\n",
    "        \"resize_in\": f\"{Himg}x{Wimg}\",\n",
    "        \"mask_type\": f\"soft (prob) saved as .npy ({Himg}x{Wimg})\",\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(SAVE_ROOT, \"META\", \"segmenter.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "csv_path = os.path.join(SAVE_ROOT, \"META\", \"index.csv\")\n",
    "# Thu gọn cột CSV\n",
    "csv_cols = [\"split\",\"label\",\"orig_path\",\"mask_soft_path\", \"H\",\"W\",\n",
    "            \"seg_model\",\"weights_sha256\", \"resize_in\"]\n",
    "csv_f = open(csv_path, \"w\", newline=\"\")\n",
    "csv_w = csv.DictWriter(csv_f, fieldnames=csv_cols)\n",
    "csv_w.writeheader()\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Loop qua train/val/test & NORMAL/PNEUMONIA (Đã thu gọn)\n",
    "# ----------------------------\n",
    "splits = [d for d in [\"train\",\"val\",\"test\"] if os.path.isdir(os.path.join(DATA_ROOT,d))]\n",
    "labels = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_soft_mask(img_np):\n",
    "    x = preprocess_resize(img_np, Himg, Wimg, DEVICE)\n",
    "    kl, xHat = model(x)\n",
    "    if (xHat.min() < 0.0) or (xHat.max() > 1.0):\n",
    "        xHat = torch.sigmoid(xHat)\n",
    "    prob = xHat.squeeze(0).squeeze(0).detach().cpu().numpy()  # (Himg,Wimg)\n",
    "    return prob\n",
    "\n",
    "for split in splits:\n",
    "    for label in labels:\n",
    "        in_dir = os.path.join(DATA_ROOT, split, label)\n",
    "        if not os.path.isdir(in_dir): \n",
    "            continue\n",
    "\n",
    "        # base2 bây giờ trỏ thẳng đến thư mục .../mask_soft/\n",
    "        base2_mask_soft = ensure_dirs(SAVE_ROOT, split, label) \n",
    "        files = sorted([f for f in os.listdir(in_dir) if is_image_file(f)])\n",
    "        print(f\"[INFO] {split}/{label}: {len(files)} files\")\n",
    "\n",
    "        for fname in tqdm(files):\n",
    "            src_path = os.path.join(in_dir, fname)\n",
    "            img = read_gray(src_path)\n",
    "            H0, W0 = img.shape[:2]\n",
    "\n",
    "            # 1. Dự đoán soft mask (model size)\n",
    "            prob_small = predict_soft_mask(img)\n",
    "\n",
    "            # ----- Chỉ lưu file mask mềm -----\n",
    "            name = os.path.splitext(fname)[0]\n",
    "            \n",
    "            # 2. Lưu mask mềm\n",
    "            out_mask_soft = os.path.join(base2_mask_soft, f\"{name}_mask_soft.npy\")\n",
    "            np.save(out_mask_soft, prob_small.astype(np.float16))\n",
    "\n",
    "            # 3. Ghi CSV (relative paths)\n",
    "            row = {\n",
    "                \"split\": split,\n",
    "                \"label\": 0 if label==\"NORMAL\" else 1,\n",
    "                \"orig_path\": src_path,\n",
    "                \"mask_soft_path\": os.path.relpath(out_mask_soft, SAVE_ROOT),\n",
    "                \"H\": H0, \"W\": W0,\n",
    "                \"seg_model\": \"uVAE (LungVAE)\",\n",
    "                \"weights_sha256\": weights_sha,\n",
    "                \"resize_in\": f\"{Himg}x{Wimg}\",\n",
    "            }\n",
    "            csv_w.writerow(row)\n",
    "\n",
    "csv_f.close()\n",
    "print(\"[DONE] Wrote dataset to:\", SAVE_ROOT)\n",
    "print(\" - META/segmenter.json\")\n",
    "print(\" - META/index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e4101",
   "metadata": {
    "papermill": {
     "duration": 0.077331,
     "end_time": "2025-10-27T16:57:53.495993",
     "exception": false,
     "start_time": "2025-10-27T16:57:53.418662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8382781,
     "sourceId": 13225061,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 255.933828,
   "end_time": "2025-10-27T16:57:54.592372",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-27T16:53:38.658544",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
