{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport pandas as pd\nfrom collections import Counter"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Tải tất cả các thư viện cần thiết cho phân tích, xử lý và huấn luyện mô hình.\n\n### Đề xuất (Pipeline):\n* Cell này nên được giữ ở đầu pipeline."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 1. Phân tích Kích thước Ảnh Gốc\n\nKiểm tra xem các ảnh gốc có đồng nhất về kích thước không. *Đây là bước phân tích, không phải bước xử lý.*"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\n# Định nghĩa đường dẫn (từ cell 6 của file gốc)\nTRAIN_PATH = '../input/chest-xray-pneumonia/chest_xray/train'\nTEST_PATH = '../input/chest-xray-pneumonia/chest_xray/test'\nVAL_PATH = '../input/chest-xray-pneumonia/chest_xray/val'\nPATHS = {'train': TRAIN_PATH, 'test': TEST_PATH, 'val': VAL_PATH}\nLABELS = ['PNEUMONIA', 'NORMAL']\n\ndef get_original_image_sizes(data_path):\n    sizes = []\n    if not os.path.exists(data_path):\n        print(f\"Đường dẫn không tồn tại: {data_path}\")\n        return Counter()\n        \n    for label in LABELS:\n        path = os.path.join(data_path, label)\n        if not os.path.exists(path):\n            continue\n            \n        for img_file in os.listdir(path):\n            try:\n                img_path = os.path.join(path, img_file)\n                # Chỉ đọc header để lấy kích thước, không đọc cả ảnh -> nhanh hơn\n                img = cv2.imread(img_path)\n                if img is not None:\n                    sizes.append(img.shape[:2]) # (height, width)\n                else:\n                    print(f\"Không thể đọc file: {img_path}\")\n            except Exception as e:\n                print(f\"Lỗi file {img_path}: {e}\")\n    return Counter(sizes)\n\nfor name, path in PATHS.items():\n    print(f\"--- Đang quét tập {name} ---\")\n    size_counts = get_original_image_sizes(path)\n    if size_counts:\n        print(f\"Các kích thước ảnh tìm thấy: {len(size_counts)} kích thước khác nhau\")\n        print(size_counts.most_common(5)) # In 5 kích thước phổ biến nhất\n    else:\n        print(\"Không tìm thấy dữ liệu.\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Cell code trên quét các file ảnh gốc và thống kê tất cả các kích thước (height, width) của chúng.\n* **Kết quả:** Rất có thể bạn sẽ thấy **rất nhiều kích thước khác nhau**. Điều này khẳng định rằng dữ liệu đầu vào không đồng nhất.\n\n### Đề xuất (Pipeline):\n* **Bắt buộc:** Phải có một bước **Resize** đồng nhất tất cả ảnh về một kích thước cố định trước khi đưa vào model.\n* **Lựa chọn:**\n    * `150x150` (như trong file gốc của bạn): Tốt, nhanh, nhưng có thể mất chi tiết.\n    * `224x224` (Tiêu chuẩn): Kích thước phổ biến cho ResNet, VGG. Đây là lựa chọn an toàn.\n    * `299x299` (Cho Inception) hoặc lớn hơn (Cho EfficientNet)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 2. Phân tích Phân chia Dữ liệu (Train/Val/Test)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\ndef count_files(data_path):\n    count = 0\n    if not os.path.exists(data_path): return 0\n    for label in LABELS:\n        path = os.path.join(data_path, label)\n        if not os.path.exists(path): continue\n        count += len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n    return count\n\ntrain_size = count_files(TRAIN_PATH)\ntest_size = count_files(TEST_PATH)\nval_size = count_files(VAL_PATH)\n\nprint(f\"Train: {train_size}, Test: {test_size}, Val: {val_size}\")\n\nsizes = [train_size, test_size, val_size]\nsplit_labels = ['Train', 'Test', 'Validation']\ncolors = ['orange', 'lightblue', 'white']\nexplode = (0, 0, 0.1)\n\nplt.figure(figsize=(6,6))\nwedges, texts, autotexts = plt.pie(\n    sizes, labels=split_labels, colors=colors, autopct='%1.1f%%',\n    explode=explode, startangle=90, wedgeprops={'edgecolor':'black'}\n)\nplt.title('Tỷ lệ phân chia Train/Test/Validation', fontsize=16)\nplt.legend(wedges, split_labels, title=\"Tập\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\nplt.axis('equal')\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Biểu đồ tròn cho thấy tỷ lệ phân chia dữ liệu.\n* **Phân tích:** Tập `Validation` chỉ chiếm `1.1%` (từ file gốc). Đây là một con số **cực kỳ nhỏ** và **rất nguy hiểm**. Đánh giá model trên một tập val nhỏ như vậy sẽ không đáng tin cậy, kết quả sẽ bị dao động (variance) rất lớn.\n\n### Đề xuất (Pipeline):\n* **Hành động:** Gộp tập `train` và `val` gốc lại thành một bộ dữ liệu lớn.\n* Sau đó, chia lại (resplit) bộ dữ liệu lớn này thành 2 tập (hoặc 3 tập) mới theo tỷ lệ 80/20 (Train/Val) hoặc 70/20/10 (Train/Val/Test). Sử dụng `sklearn.model_selection.train_test_split` để chia."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 3. Phân tích Cân bằng Lớp (Class Balance)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\ndef get_class_distribution(data_path):\n    dist = {}\n    for label in LABELS:\n        path = os.path.join(data_path, label)\n        if not os.path.exists(path): continue\n        count = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n        dist[label] = count\n    return dist\n\ntrain_dist = get_class_distribution(TRAIN_PATH)\nprint(f\"Phân bổ lớp (Train): {train_dist}\")\n\nplt.figure(figsize=(6,4))\nax = sns.barplot(x=list(train_dist.keys()), y=list(train_dist.values()), palette=\"Set2\")\n# (Phần code annotate từ cell 8 gốc)\nfor p in ax.patches:\n    height = int(p.get_height())\n    ax.annotate(f'{height}', \n                (p.get_x() + p.get_width() / 2., height + 50),  \n                ha='center', va='bottom', fontsize=12, color='black', fontweight='bold')\nplt.title(\"Class distribution (Train set)\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Count\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Biểu đồ cho thấy số lượng ảnh của mỗi lớp trong tập train.\n* **Phân tích:** Dữ liệu bị **mất cân bằng (imbalanced)** nghiêm trọng. Lớp 'PNEUMONIA' có số lượng ảnh gấp khoảng 3 lần lớp 'NORMAL'.\n* Điều này sẽ khiến model bị thiên vị, có xu hướng dự đoán 'PNEUMONIA' nhiều hơn, và có thể đạt độ chính xác cao giả tạo (vì nó đoán đúng phần lớn các ca 'PNEUMONIA' nhưng lại đoán sai nhiều ca 'NORMAL').\n\n### Đề xuất (Pipeline):\n* **Giải pháp 1 (Nên làm):** Sử dụng **Data Augmentation** (Tăng cường dữ liệu) nhiều hơn cho lớp 'NORMAL' (lớp thiểu số).\n* **Giải pháp 2 (Nên làm):** Khi gọi `model.fit()`, hãy cung cấp tham số `class_weight`. Tính toán `class_weight` để 'trừng phạt' model nặng hơn khi nó dự đoán sai lớp 'NORMAL'.\n* **Giải pháp 3 (Tùy chọn):** Áp dụng kỹ thuật Oversampling (ví dụ: SMOTE) cho lớp 'NORMAL' hoặc Undersampling cho lớp 'PNEUMONIA'."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 4. Trực quan hóa Ảnh mẫu\n\n(Phần này cần dữ liệu đã được tải, nên ta sẽ định nghĩa hàm tải trước)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 5. Đề xuất Pipeline Xử lý Dữ liệu\n\n*Các cell dưới đây là các bước xử lý dữ liệu, được tổ chức lại từ file gốc của bạn.*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.1. Định nghĩa Hàm Tải & Resize Dữ liệu"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 150\n\ndef get_training_data(data_dir):\n    images = []\n    target = []\n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                if img_arr is None:  # tránh lỗi resize NoneType\n                    continue\n                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n                images.append(resized_arr)\n                target.append(class_num)\n            except Exception as e:\n                print(f\"Lỗi khi xử lý ảnh {img}: {e}\")\n    \n    return images, target"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Đây là hàm chính để tải dữ liệu. Quan trọng là, hàm này **đọc ảnh (GRAYSCALE) và RESIZE về `150x150` ngay lập tức** (`img_size = 150`).\n\n### Đề xuất (Pipeline):\n* Giữ nguyên hàm này. Kích thước `150x150` là một lựa chọn hợp lý để bắt đầu.\n* **Lưu ý:** Vì ảnh được đọc ở dạng `GRAYSCALE` (1 kênh), model ở cuối phải có `input_shape = (150, 150, 1)`."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.2. Tải Dữ liệu vào Bộ nhớ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Gọi hàm\nx_train, y_train = get_training_data('../input/chest-xray-pneumonia/chest_xray/train')\nx_test, y_test   = get_training_data('../input/chest-xray-pneumonia/chest_xray/test')\nx_val, y_val     = get_training_data('../input/chest-xray-pneumonia/chest_xray/val')\n\nprint(x_train.shape, y_train.shape)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Tải dữ liệu vào các biến `x_train`, `y_train`...\n* **Lưu ý:** Như đã phân tích ở mục 2, tập `x_val`, `y_val` là **quá nhỏ**. Bạn nên cân nhắc gộp và chia lại."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.3. Trực quan hóa (Sau khi tải dữ liệu)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plt.figure(figsize=(5,5))\nplt.imshow(x_train[0], cmap='viridis')\nplt.title(labels[y_train[0]])\n\nplt.figure(figsize=(5,5))\nplt.imshow(x_train[-1], cmap='viridis')\nplt.title(labels[y_train[-1]])\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n\n# lấy 5 ảnh PNEUMONIA\npneumonia_samples = x_train[y_train == 0][:5]\nfor i, ax in enumerate(axes[0]):\n    ax.imshow(pneumonia_samples[i], cmap='gray')\n    ax.set_title(\"PNEUMONIA\")\n    ax.axis('off')\n\n# lấy 5 ảnh NORMAL\nnormal_samples = x_train[y_train == 1][:5]\nfor i, ax in enumerate(axes[1]):\n    ax.imshow(normal_samples[i], cmap='gray')\n    ax.set_title(\"NORMAL\")\n    ax.axis('off')\n\nplt.suptitle(\"Random samples from each class\", fontsize=16)\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plt.figure(figsize=(10,5))\nfor i, lab in enumerate(labels):\n    pixels = x_train[y_train==i].ravel()\n    sns.histplot(pixels, bins=50, kde=True, label=lab, alpha=0.6)\nplt.legend()\nplt.title(\"Pixel Intensity Distribution per Class (Train set)\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Trực quan hóa một vài ảnh mẫu và phân bổ pixel. Giúp kiểm tra xem dữ liệu có bị lỗi, nhiễu, hay có gì bất thường không.\n* **Phân tích:** Ảnh X-quang phổi, có vẻ rõ ràng.\n\n### Đề xuất (Pipeline):\n* Giữ nguyên các bước trực quan hóa này để kiểm tra (sanity check)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.4. Chuẩn hóa (Normalization) và Reshape"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convert sang numpy array\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n\nx_val = np.array(x_val)\ny_val = np.array(y_val)\n\nx_test = np.array(x_test)\ny_test = np.array(y_test)\n\n# Normalize the data\nx_train = x_train / 255.0\nx_val   = x_val / 255.0\nx_test  = x_test / 255.0\n\nx_train = x_train.reshape(-1, img_size, img_size, 1)\nx_val   = x_val.reshape(-1, img_size, img_size, 1)\nx_test  = x_test.reshape(-1, img_size, img_size, 1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* **Cell 1 (np.array):** Chuyển list ảnh sang mảng NumPy để xử lý.\n* **Cell 2 (Normalization):** Chia pixel cho 255.0 để đưa giá trị về khoảng `[0, 1]`. Đây là bước **bắt buộc** cho các mạng neural network.\n* **Cell 3 (Reshape):** Thêm một chiều kênh (channel) vào cuối, đổi shape từ `(N, 150, 150)` thành `(N, 150, 150, 1)`. Đây là bước **bắt buộc** vì Keras Conv2D yêu cầu đầu vào 4D.\n\n### Đề xuất (Pipeline):\n* Gộp 3 bước này lại và giữ nguyên, đây là các bước chuẩn."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.5. Tăng cường Dữ liệu (Data Augmentation)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "data_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndata_generator.fit(x_train)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ý nghĩa:\n* Định nghĩa một `ImageDataGenerator` để tạo thêm dữ liệu huấn luyện bằng cách xoay, zoom, lật ảnh ngẫu nhiên. Giúp model tổng quát hóa tốt hơn và giảm overfitting.\n\n### Đề xuất (Pipeline):\n* **Quan trọng:** Đây là giải pháp tốt cho vấn đề mất cân bằng lớp (mục 3). Bạn có thể tạo 2 generator: 1 cho 'PNEUMONIA' với các phép biến đổi nhẹ, và 1 cho 'NORMAL' (lớp thiểu số) với các phép biến đổi mạnh hơn (xoay nhiều hơn, zoom nhiều hơn) để tạo ra nhiều dữ liệu 'NORMAL' đa dạng hơn."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}